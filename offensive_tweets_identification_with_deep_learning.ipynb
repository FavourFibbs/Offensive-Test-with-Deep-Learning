{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b313d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sochima\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fac4b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('olid-training-v1.0.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d199e725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16820</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43605</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>95338</td>\n",
       "      <td>@USER Sometimes I get strong vibes from people...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>67210</td>\n",
       "      <td>Benidorm ✅  Creamfields ✅  Maga ✅   Not too sh...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>82921</td>\n",
       "      <td>@USER And why report this garbage.  We don't g...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>27429</td>\n",
       "      <td>@USER Pussy</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>46552</td>\n",
       "      <td>#Spanishrevenge vs. #justice #HumanRights and ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet subtask_a  \\\n",
       "0      86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "1      90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
       "2      16820  Amazon is investigating Chinese employees who ...       NOT   \n",
       "3      62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
       "4      43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
       "...      ...                                                ...       ...   \n",
       "13235  95338  @USER Sometimes I get strong vibes from people...       OFF   \n",
       "13236  67210  Benidorm ✅  Creamfields ✅  Maga ✅   Not too sh...       NOT   \n",
       "13237  82921  @USER And why report this garbage.  We don't g...       OFF   \n",
       "13238  27429                                        @USER Pussy       OFF   \n",
       "13239  46552  #Spanishrevenge vs. #justice #HumanRights and ...       NOT   \n",
       "\n",
       "      subtask_b subtask_c  \n",
       "0           UNT       NaN  \n",
       "1           TIN       IND  \n",
       "2           NaN       NaN  \n",
       "3           UNT       NaN  \n",
       "4           NaN       NaN  \n",
       "...         ...       ...  \n",
       "13235       TIN       IND  \n",
       "13236       NaN       NaN  \n",
       "13237       TIN       OTH  \n",
       "13238       UNT       NaN  \n",
       "13239       NaN       NaN  \n",
       "\n",
       "[13240 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf13181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
    "    text = re.sub(r'#\\w+', '', text)  # Remove hashtags\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove punctuation and numbers\n",
    "    text = text.lower().strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b8aeea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_tweet'] = data['tweet'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12c844c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>she should ask a few native americans what the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>go home youre drunk     url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16820</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amazon is investigating chinese employees who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>someone shouldvetaken this piece of shit to a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43605</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>obama wanted liberals amp illegals to move int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>95338</td>\n",
       "      <td>@USER Sometimes I get strong vibes from people...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>sometimes i get strong vibes from people and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>67210</td>\n",
       "      <td>Benidorm ✅  Creamfields ✅  Maga ✅   Not too sh...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>benidorm   creamfields   maga    not too shabb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>82921</td>\n",
       "      <td>@USER And why report this garbage.  We don't g...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "      <td>and why report this garbage  we dont give a crap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>27429</td>\n",
       "      <td>@USER Pussy</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pussy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>46552</td>\n",
       "      <td>#Spanishrevenge vs. #justice #HumanRights and ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vs   and   is a                      url</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet subtask_a  \\\n",
       "0      86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "1      90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
       "2      16820  Amazon is investigating Chinese employees who ...       NOT   \n",
       "3      62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
       "4      43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
       "...      ...                                                ...       ...   \n",
       "13235  95338  @USER Sometimes I get strong vibes from people...       OFF   \n",
       "13236  67210  Benidorm ✅  Creamfields ✅  Maga ✅   Not too sh...       NOT   \n",
       "13237  82921  @USER And why report this garbage.  We don't g...       OFF   \n",
       "13238  27429                                        @USER Pussy       OFF   \n",
       "13239  46552  #Spanishrevenge vs. #justice #HumanRights and ...       NOT   \n",
       "\n",
       "      subtask_b subtask_c                                      cleaned_tweet  \n",
       "0           UNT       NaN  she should ask a few native americans what the...  \n",
       "1           TIN       IND                        go home youre drunk     url  \n",
       "2           NaN       NaN  amazon is investigating chinese employees who ...  \n",
       "3           UNT       NaN  someone shouldvetaken this piece of shit to a ...  \n",
       "4           NaN       NaN  obama wanted liberals amp illegals to move int...  \n",
       "...         ...       ...                                                ...  \n",
       "13235       TIN       IND  sometimes i get strong vibes from people and t...  \n",
       "13236       NaN       NaN  benidorm   creamfields   maga    not too shabb...  \n",
       "13237       TIN       OTH   and why report this garbage  we dont give a crap  \n",
       "13238       UNT       NaN                                              pussy  \n",
       "13239       NaN       NaN           vs   and   is a                      url  \n",
       "\n",
       "[13240 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "065accb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "data['label'] = label_encoder.fit_transform(data['subtask_a'].fillna('NOT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e785e5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>she should ask a few native americans what the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>go home youre drunk     url</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16820</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amazon is investigating chinese employees who ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>someone shouldvetaken this piece of shit to a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43605</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>obama wanted liberals amp illegals to move int...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>95338</td>\n",
       "      <td>@USER Sometimes I get strong vibes from people...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>sometimes i get strong vibes from people and t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>67210</td>\n",
       "      <td>Benidorm ✅  Creamfields ✅  Maga ✅   Not too sh...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>benidorm   creamfields   maga    not too shabb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>82921</td>\n",
       "      <td>@USER And why report this garbage.  We don't g...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "      <td>and why report this garbage  we dont give a crap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>27429</td>\n",
       "      <td>@USER Pussy</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pussy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>46552</td>\n",
       "      <td>#Spanishrevenge vs. #justice #HumanRights and ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vs   and   is a                      url</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet subtask_a  \\\n",
       "0      86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "1      90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
       "2      16820  Amazon is investigating Chinese employees who ...       NOT   \n",
       "3      62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
       "4      43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
       "...      ...                                                ...       ...   \n",
       "13235  95338  @USER Sometimes I get strong vibes from people...       OFF   \n",
       "13236  67210  Benidorm ✅  Creamfields ✅  Maga ✅   Not too sh...       NOT   \n",
       "13237  82921  @USER And why report this garbage.  We don't g...       OFF   \n",
       "13238  27429                                        @USER Pussy       OFF   \n",
       "13239  46552  #Spanishrevenge vs. #justice #HumanRights and ...       NOT   \n",
       "\n",
       "      subtask_b subtask_c                                      cleaned_tweet  \\\n",
       "0           UNT       NaN  she should ask a few native americans what the...   \n",
       "1           TIN       IND                        go home youre drunk     url   \n",
       "2           NaN       NaN  amazon is investigating chinese employees who ...   \n",
       "3           UNT       NaN  someone shouldvetaken this piece of shit to a ...   \n",
       "4           NaN       NaN  obama wanted liberals amp illegals to move int...   \n",
       "...         ...       ...                                                ...   \n",
       "13235       TIN       IND  sometimes i get strong vibes from people and t...   \n",
       "13236       NaN       NaN  benidorm   creamfields   maga    not too shabb...   \n",
       "13237       TIN       OTH   and why report this garbage  we dont give a crap   \n",
       "13238       UNT       NaN                                              pussy   \n",
       "13239       NaN       NaN           vs   and   is a                      url   \n",
       "\n",
       "       label  \n",
       "0          1  \n",
       "1          1  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  \n",
       "...      ...  \n",
       "13235      1  \n",
       "13236      0  \n",
       "13237      1  \n",
       "13238      1  \n",
       "13239      0  \n",
       "\n",
       "[13240 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82d3bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing over sampling on the dataset\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "over_sampler = RandomOverSampler(sampling_strategy='auto',random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1055d97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(data['cleaned_tweet'].values.reshape(-1, 1), data['label'])\n",
    "X_train_ros = X_train_ros.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88b64ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sochima\\AppData\\Local\\Temp\\ipykernel_4624\\4205087851.py:2: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(x=y_train_ros, palette=['green','orange'])\n",
      "C:\\Users\\Sochima\\anaconda3\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\Sochima\\anaconda3\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Displaying the balanced data after over sampling\n",
    "sns.countplot(x=y_train_ros, palette=['green','orange'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "687f08a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_ros,y_train_ros, test_size=0.2, random_state=44, stratify=y_train_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47911f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a49cc522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding sequences\n",
    "max_len = 100\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ed47d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define embedding dimensions\n",
    "embedding_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10d9acf",
   "metadata": {},
   "source": [
    "# Word Embedding Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8574d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GloVe embeddings\n",
    "glove_file = 'glove.6B.100d.txt'\n",
    "word2vec_glove_file = 'glove.6B.100d.word2vec.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d786f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.exists(glove_file):\n",
    "    raise FileNotFoundError(f\"{glove_file} not found. Please download it from https://nlp.stanford.edu/projects/glove/ and place it in the working directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69f305de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sochima\\AppData\\Local\\Temp\\ipykernel_4624\\2220563736.py:1: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_file, word2vec_glove_file)\n"
     ]
    }
   ],
   "source": [
    "glove2word2vec(glove_file, word2vec_glove_file)\n",
    "glove_model = KeyedVectors.load_word2vec_format(word2vec_glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2aade467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GloVe embedding matrix\n",
    "glove_embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in glove_model:\n",
    "        glove_embedding_matrix[i] = glove_model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c195ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "sentences = [tweet.split() for tweet in X_train]\n",
    "word2vec_model = Word2Vec(sentences, vector_size=embedding_dim, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13b689dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Word2Vec embedding matrix\n",
    "word2vec_embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in word2vec_model.wv:\n",
    "        word2vec_embedding_matrix[i] = word2vec_model.wv[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60c13bf",
   "metadata": {},
   "source": [
    "# Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "696d50a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "def create_simple_nn(embedding_matrix):\n",
    "    model = Sequential([\n",
    "        Embedding(len(tokenizer.word_index) + 1, embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False),\n",
    "        Flatten(),\n",
    "        Dense(10, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30054161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(embedding_matrix):\n",
    "    model = Sequential([\n",
    "        Embedding(len(tokenizer.word_index) + 1, embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False),\n",
    "        LSTM(100, return_sequences=True),\n",
    "        LSTM(100),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ca08e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(embedding_matrix):\n",
    "    model = Sequential([\n",
    "        Embedding(len(tokenizer.word_index) + 1, embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False),\n",
    "        Conv1D(128, 5, activation='relu'),\n",
    "        MaxPooling1D(pool_size=4),\n",
    "        Flatten(),\n",
    "        Dense(10, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29ea5293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train models for GloVe\n",
    "models_glove = {\n",
    "    'simple_nn': create_simple_nn(glove_embedding_matrix),\n",
    "    'lstm': create_lstm_model(glove_embedding_matrix),\n",
    "    'cnn': create_cnn_model(glove_embedding_matrix)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2c84645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training simple_nn model with GloVe embeddings...\n",
      "Epoch 1/10\n",
      "442/442 [==============================] - 3s 6ms/step - loss: 0.6114 - accuracy: 0.6599 - val_loss: 0.5652 - val_accuracy: 0.7217\n",
      "Epoch 2/10\n",
      "442/442 [==============================] - 2s 6ms/step - loss: 0.4971 - accuracy: 0.7653 - val_loss: 0.5278 - val_accuracy: 0.7463\n",
      "Epoch 3/10\n",
      "442/442 [==============================] - 2s 6ms/step - loss: 0.4305 - accuracy: 0.8056 - val_loss: 0.5166 - val_accuracy: 0.7574\n",
      "Epoch 4/10\n",
      "442/442 [==============================] - 2s 6ms/step - loss: 0.3779 - accuracy: 0.8382 - val_loss: 0.5075 - val_accuracy: 0.7721\n",
      "Epoch 5/10\n",
      "442/442 [==============================] - 3s 6ms/step - loss: 0.3308 - accuracy: 0.8622 - val_loss: 0.4980 - val_accuracy: 0.7828\n",
      "Epoch 6/10\n",
      "442/442 [==============================] - 3s 6ms/step - loss: 0.2880 - accuracy: 0.8847 - val_loss: 0.5127 - val_accuracy: 0.7794\n",
      "Epoch 7/10\n",
      "442/442 [==============================] - 2s 6ms/step - loss: 0.2476 - accuracy: 0.9023 - val_loss: 0.5580 - val_accuracy: 0.7786\n",
      "Epoch 8/10\n",
      "442/442 [==============================] - 2s 6ms/step - loss: 0.2163 - accuracy: 0.9160 - val_loss: 0.5351 - val_accuracy: 0.7984\n",
      "Epoch 9/10\n",
      "442/442 [==============================] - 3s 6ms/step - loss: 0.1874 - accuracy: 0.9297 - val_loss: 0.5623 - val_accuracy: 0.7921\n",
      "Epoch 10/10\n",
      "442/442 [==============================] - 2s 6ms/step - loss: 0.1627 - accuracy: 0.9427 - val_loss: 0.5676 - val_accuracy: 0.8054\n",
      "Training lstm model with GloVe embeddings...\n",
      "Epoch 1/10\n",
      "442/442 [==============================] - 81s 174ms/step - loss: 0.5678 - accuracy: 0.6999 - val_loss: 0.4990 - val_accuracy: 0.7613\n",
      "Epoch 2/10\n",
      "442/442 [==============================] - 76s 172ms/step - loss: 0.4975 - accuracy: 0.7612 - val_loss: 0.4912 - val_accuracy: 0.7551\n",
      "Epoch 3/10\n",
      "442/442 [==============================] - 75s 169ms/step - loss: 0.4691 - accuracy: 0.7784 - val_loss: 0.4800 - val_accuracy: 0.7653\n",
      "Epoch 4/10\n",
      "442/442 [==============================] - 75s 169ms/step - loss: 0.4394 - accuracy: 0.7976 - val_loss: 0.4565 - val_accuracy: 0.7845\n",
      "Epoch 5/10\n",
      "442/442 [==============================] - 75s 169ms/step - loss: 0.3988 - accuracy: 0.8235 - val_loss: 0.4498 - val_accuracy: 0.7896\n",
      "Epoch 6/10\n",
      "442/442 [==============================] - 76s 171ms/step - loss: 0.3485 - accuracy: 0.8474 - val_loss: 0.4501 - val_accuracy: 0.8020\n",
      "Epoch 7/10\n",
      "442/442 [==============================] - 87s 198ms/step - loss: 0.2916 - accuracy: 0.8772 - val_loss: 0.4558 - val_accuracy: 0.8074\n",
      "Epoch 8/10\n",
      "442/442 [==============================] - 75s 170ms/step - loss: 0.2313 - accuracy: 0.9083 - val_loss: 0.4807 - val_accuracy: 0.8232\n",
      "Epoch 9/10\n",
      "442/442 [==============================] - 75s 170ms/step - loss: 0.1761 - accuracy: 0.9318 - val_loss: 0.5208 - val_accuracy: 0.8281\n",
      "Epoch 10/10\n",
      "442/442 [==============================] - 82s 185ms/step - loss: 0.1256 - accuracy: 0.9541 - val_loss: 0.5411 - val_accuracy: 0.8312\n",
      "Training cnn model with GloVe embeddings...\n",
      "Epoch 1/10\n",
      "442/442 [==============================] - 12s 25ms/step - loss: 0.5683 - accuracy: 0.7029 - val_loss: 0.4907 - val_accuracy: 0.7681\n",
      "Epoch 2/10\n",
      "442/442 [==============================] - 10s 24ms/step - loss: 0.4407 - accuracy: 0.8027 - val_loss: 0.4557 - val_accuracy: 0.7907\n",
      "Epoch 3/10\n",
      "442/442 [==============================] - 11s 24ms/step - loss: 0.3367 - accuracy: 0.8657 - val_loss: 0.5526 - val_accuracy: 0.7610\n",
      "Epoch 4/10\n",
      "442/442 [==============================] - 10s 24ms/step - loss: 0.2270 - accuracy: 0.9124 - val_loss: 0.4415 - val_accuracy: 0.8264\n",
      "Epoch 5/10\n",
      "442/442 [==============================] - 11s 24ms/step - loss: 0.1378 - accuracy: 0.9535 - val_loss: 0.4823 - val_accuracy: 0.8380\n",
      "Epoch 6/10\n",
      "442/442 [==============================] - 10s 24ms/step - loss: 0.0936 - accuracy: 0.9690 - val_loss: 0.5331 - val_accuracy: 0.8430\n",
      "Epoch 7/10\n",
      "442/442 [==============================] - 11s 25ms/step - loss: 0.0676 - accuracy: 0.9786 - val_loss: 0.5858 - val_accuracy: 0.8357\n",
      "Epoch 8/10\n",
      "442/442 [==============================] - 11s 24ms/step - loss: 0.0462 - accuracy: 0.9864 - val_loss: 0.6063 - val_accuracy: 0.8555\n",
      "Epoch 9/10\n",
      "442/442 [==============================] - 11s 24ms/step - loss: 0.0464 - accuracy: 0.9852 - val_loss: 0.6338 - val_accuracy: 0.8476\n",
      "Epoch 10/10\n",
      "442/442 [==============================] - 12s 26ms/step - loss: 0.0549 - accuracy: 0.9803 - val_loss: 0.7310 - val_accuracy: 0.8470\n"
     ]
    }
   ],
   "source": [
    "histories_glove = {}\n",
    "for name, model in models_glove.items():\n",
    "    print(f\"Training {name} model with GloVe embeddings...\")\n",
    "    histories_glove[name] = model.fit(X_train_pad, y_train, epochs=10, batch_size=32, validation_data=(X_test_pad, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03b6fbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train models for Word2Vec\n",
    "models_word2vec = {\n",
    "    'simple_nn': create_simple_nn(word2vec_embedding_matrix),\n",
    "    'lstm': create_lstm_model(word2vec_embedding_matrix),\n",
    "    'cnn': create_cnn_model(word2vec_embedding_matrix)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7072b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training simple_nn model with Word2Vec embeddings...\n",
      "Epoch 1/10\n",
      "442/442 [==============================] - 4s 8ms/step - loss: 0.6851 - accuracy: 0.5480 - val_loss: 0.6798 - val_accuracy: 0.5563\n",
      "Epoch 2/10\n",
      "442/442 [==============================] - 4s 8ms/step - loss: 0.6777 - accuracy: 0.5669 - val_loss: 0.6764 - val_accuracy: 0.5650\n",
      "Epoch 3/10\n",
      "442/442 [==============================] - 3s 7ms/step - loss: 0.6707 - accuracy: 0.5809 - val_loss: 0.6753 - val_accuracy: 0.5642\n",
      "Epoch 4/10\n",
      "442/442 [==============================] - 3s 7ms/step - loss: 0.6645 - accuracy: 0.5936 - val_loss: 0.6721 - val_accuracy: 0.5631\n",
      "Epoch 5/10\n",
      "442/442 [==============================] - 4s 8ms/step - loss: 0.6585 - accuracy: 0.5944 - val_loss: 0.6851 - val_accuracy: 0.5639\n",
      "Epoch 6/10\n",
      "442/442 [==============================] - 3s 7ms/step - loss: 0.6538 - accuracy: 0.6017 - val_loss: 0.6728 - val_accuracy: 0.5735\n",
      "Epoch 7/10\n",
      "442/442 [==============================] - 2s 5ms/step - loss: 0.6477 - accuracy: 0.6069 - val_loss: 0.6754 - val_accuracy: 0.5625\n",
      "Epoch 8/10\n",
      "442/442 [==============================] - 3s 6ms/step - loss: 0.6431 - accuracy: 0.6116 - val_loss: 0.6784 - val_accuracy: 0.5761\n",
      "Epoch 9/10\n",
      "442/442 [==============================] - 3s 6ms/step - loss: 0.6375 - accuracy: 0.6140 - val_loss: 0.6731 - val_accuracy: 0.5713\n",
      "Epoch 10/10\n",
      "442/442 [==============================] - 2s 6ms/step - loss: 0.6333 - accuracy: 0.6186 - val_loss: 0.6754 - val_accuracy: 0.5682\n",
      "Training lstm model with Word2Vec embeddings...\n",
      "Epoch 1/10\n",
      "442/442 [==============================] - 102s 218ms/step - loss: 0.6854 - accuracy: 0.5502 - val_loss: 0.6703 - val_accuracy: 0.5806\n",
      "Epoch 2/10\n",
      "442/442 [==============================] - 77s 174ms/step - loss: 0.6692 - accuracy: 0.5830 - val_loss: 0.6630 - val_accuracy: 0.5950\n",
      "Epoch 3/10\n",
      "442/442 [==============================] - 78s 176ms/step - loss: 0.6607 - accuracy: 0.5970 - val_loss: 0.6544 - val_accuracy: 0.6089\n",
      "Epoch 4/10\n",
      "442/442 [==============================] - 77s 175ms/step - loss: 0.6536 - accuracy: 0.6078 - val_loss: 0.6474 - val_accuracy: 0.6145\n",
      "Epoch 5/10\n",
      "442/442 [==============================] - 81s 183ms/step - loss: 0.6442 - accuracy: 0.6169 - val_loss: 0.6447 - val_accuracy: 0.6191\n",
      "Epoch 6/10\n",
      "442/442 [==============================] - 77s 174ms/step - loss: 0.6346 - accuracy: 0.6314 - val_loss: 0.6348 - val_accuracy: 0.6222\n",
      "Epoch 7/10\n",
      "442/442 [==============================] - 89s 201ms/step - loss: 0.6219 - accuracy: 0.6441 - val_loss: 0.6278 - val_accuracy: 0.6369\n",
      "Epoch 8/10\n",
      "442/442 [==============================] - 77s 175ms/step - loss: 0.6253 - accuracy: 0.6429 - val_loss: 0.6523 - val_accuracy: 0.6072\n",
      "Epoch 9/10\n",
      "442/442 [==============================] - 77s 174ms/step - loss: 0.6092 - accuracy: 0.6543 - val_loss: 0.6341 - val_accuracy: 0.6312\n",
      "Epoch 10/10\n",
      "442/442 [==============================] - 78s 176ms/step - loss: 0.5896 - accuracy: 0.6735 - val_loss: 0.6336 - val_accuracy: 0.6292\n",
      "Training cnn model with Word2Vec embeddings...\n",
      "Epoch 1/10\n",
      "442/442 [==============================] - 11s 24ms/step - loss: 0.6856 - accuracy: 0.5500 - val_loss: 0.6759 - val_accuracy: 0.5758\n",
      "Epoch 2/10\n",
      "442/442 [==============================] - 10s 23ms/step - loss: 0.6738 - accuracy: 0.5814 - val_loss: 0.6714 - val_accuracy: 0.5778\n",
      "Epoch 3/10\n",
      "442/442 [==============================] - 10s 23ms/step - loss: 0.6620 - accuracy: 0.5966 - val_loss: 0.6765 - val_accuracy: 0.5789\n",
      "Epoch 4/10\n",
      "442/442 [==============================] - 12s 27ms/step - loss: 0.6524 - accuracy: 0.6094 - val_loss: 0.6712 - val_accuracy: 0.5964\n",
      "Epoch 5/10\n",
      "442/442 [==============================] - 11s 24ms/step - loss: 0.6350 - accuracy: 0.6342 - val_loss: 0.6593 - val_accuracy: 0.6151\n",
      "Epoch 6/10\n",
      "442/442 [==============================] - 11s 24ms/step - loss: 0.6165 - accuracy: 0.6533 - val_loss: 0.6676 - val_accuracy: 0.6015\n",
      "Epoch 7/10\n",
      "442/442 [==============================] - 10s 24ms/step - loss: 0.5936 - accuracy: 0.6776 - val_loss: 0.6591 - val_accuracy: 0.6292\n",
      "Epoch 8/10\n",
      "442/442 [==============================] - 10s 23ms/step - loss: 0.5710 - accuracy: 0.6987 - val_loss: 0.6771 - val_accuracy: 0.6191\n",
      "Epoch 9/10\n",
      "442/442 [==============================] - 10s 23ms/step - loss: 0.5433 - accuracy: 0.7172 - val_loss: 0.6708 - val_accuracy: 0.6363\n",
      "Epoch 10/10\n",
      "442/442 [==============================] - 10s 23ms/step - loss: 0.5164 - accuracy: 0.7419 - val_loss: 0.6641 - val_accuracy: 0.6502\n"
     ]
    }
   ],
   "source": [
    "histories_word2vec = {}\n",
    "for name, model in models_word2vec.items():\n",
    "    print(f\"Training {name} model with Word2Vec embeddings...\")\n",
    "    histories_word2vec[name] = model.fit(X_train_pad, y_train, epochs=10, batch_size=32, validation_data=(X_test_pad, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83a4b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "def evaluate_models(models, X_test_pad, y_test):\n",
    "    for name, model in models.items():\n",
    "        y_pred = (model.predict(X_test_pad) > 0.5).astype(int)\n",
    "        print(f\"{name} Model Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd5d3341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation with GloVe embeddings:\n",
      "111/111 [==============================] - 1s 4ms/step\n",
      "simple_nn Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1768\n",
      "           1       0.82      0.78      0.80      1768\n",
      "\n",
      "    accuracy                           0.81      3536\n",
      "   macro avg       0.81      0.81      0.81      3536\n",
      "weighted avg       0.81      0.81      0.81      3536\n",
      "\n",
      "111/111 [==============================] - 9s 71ms/step\n",
      "lstm Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83      1768\n",
      "           1       0.84      0.81      0.83      1768\n",
      "\n",
      "    accuracy                           0.83      3536\n",
      "   macro avg       0.83      0.83      0.83      3536\n",
      "weighted avg       0.83      0.83      0.83      3536\n",
      "\n",
      "111/111 [==============================] - 1s 8ms/step\n",
      "cnn Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85      1768\n",
      "           1       0.85      0.84      0.85      1768\n",
      "\n",
      "    accuracy                           0.85      3536\n",
      "   macro avg       0.85      0.85      0.85      3536\n",
      "weighted avg       0.85      0.85      0.85      3536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation with GloVe embeddings:\")\n",
    "evaluate_models(models_glove, X_test_pad, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f8245da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation with Word2Vec embeddings:\n",
      "111/111 [==============================] - 0s 3ms/step\n",
      "simple_nn Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.68      0.61      1768\n",
      "           1       0.59      0.46      0.52      1768\n",
      "\n",
      "    accuracy                           0.57      3536\n",
      "   macro avg       0.57      0.57      0.56      3536\n",
      "weighted avg       0.57      0.57      0.56      3536\n",
      "\n",
      "111/111 [==============================] - 9s 72ms/step\n",
      "lstm Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.77      0.68      1768\n",
      "           1       0.68      0.49      0.57      1768\n",
      "\n",
      "    accuracy                           0.63      3536\n",
      "   macro avg       0.64      0.63      0.62      3536\n",
      "weighted avg       0.64      0.63      0.62      3536\n",
      "\n",
      "111/111 [==============================] - 1s 8ms/step\n",
      "cnn Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.69      0.66      1768\n",
      "           1       0.66      0.61      0.64      1768\n",
      "\n",
      "    accuracy                           0.65      3536\n",
      "   macro avg       0.65      0.65      0.65      3536\n",
      "weighted avg       0.65      0.65      0.65      3536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation with Word2Vec embeddings:\")\n",
    "evaluate_models(models_word2vec, X_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81598ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
